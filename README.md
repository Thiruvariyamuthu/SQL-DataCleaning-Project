# SQL Data Cleaning Project: Layoffs Dataset

## Overview
This project focuses on cleaning and analyzing the layoffs dataset using SQL. The primary goal was to process and refine the raw data, ensuring it was ready for in-depth analysis. This README provides details about the dataset, the data cleaning steps, and instructions for using the provided SQL scripts.

## Dataset
- **File:** [layoffs_dataset] (https://github.com/Thiruvariyamuthu/SQL-DataCleaning-Project/blob/ab1fde1b8dc218bfd861439aaad29c337410178e/layoffs.csv)
- **Description:** This dataset includes records of layoffs across various companies, detailing company names, the number of employees laid off, and the dates of layoffs. This file was used as the input for the data cleaning project.

## Data Cleaning Process
1. **Removed Duplicates:** Identified and eliminated duplicate records from the dataset.
2. **Standardized Data and Populated Null Values:** Corrected inconsistencies in data entries and filled in null values with appropriate data.
3. **Handled Null and Blank Values:** Reviewed remaining null or blank values, made decisions on whether to delete or impute them, and applied the necessary changes.
4. **Removed Unnecessary Columns and Rows:** Deleted columns and rows that were not required for the analysis to streamline the dataset.

## Tools Used
- SQL
- MySQL Workbench (or any other SQL client)
